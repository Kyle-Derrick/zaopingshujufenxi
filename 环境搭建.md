# 环境搭建

## 环境说明

1. 电脑操作系统windows 10专业版

2. VMware 14

3. 虚拟机操作系统CentOS 7（网络配置NAT，最小安装）

4. jdk 8

5. hadoop 2.7.5

6. hbase 1.2.4

7. mysql 5.7.25

8. zookeeper 3.4.12

   注：

   ​	1). 本人安装时所有安装包在/opt/目录下，安装目录也是，

   ​	2). 由于电脑配置不高只能带3太虚拟机，就没有配置HA了

## 一、配置linux

1. 配置网卡，静态 IP

   ```shell
   [root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens33
      
      #修改
      BOOTPROTO=static
      ONBOOT=yes
      #增加
      IPADDR=192.168.197.129
      GATEWAY=192.168.197.2
      NETMASK=255.255.255.0
      DNS1=144.144.144.144
      DNS2=1.1.1.1
      
      [root@localhost ~]# systemctl restart network.service
   ```

2. 更新yum,安装系统工具net-tools,常用工具，依赖关系

   ```shell
   [root@localhost ~]# yum -y update
   [root@localhost ~]# yum -y install net-tools
   [root@localhost ~]# yum -y install curl telnet vim wget lrzsz
   [root@localhost ~]# yum -y install gcc gcc-c++ make autoconf wget lrzsz libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5-devel libidn libidn-devel openssl openssl-devel libxslt-devel libevent-devel libtool libtool-ltdl bison gd gd-devel vim-enhanced pcre-devel zip unzip ntpdate sysstat patch bc expect rsync
   ```

3. 关闭SELINUX

   ```shell
   [root@localhost ~]# vim /etc/sysconfig/selinux
   #SELINUX=enforcing
   SELINUX=disabled
   
   [root@localhost ~]# setenforce 0
   ```

4. 设置时间时区

   ```shell
   [root@localhost ~]# yum install ntp		#安装ntp服务的软件包
   [root@localhost ~]# systemctl enable ntpd		#将ntp服务设置为缺省启动
   [root@localhost ~]# vim /etc/sysconfig/ntpd		#修改启动参数，增加-g -x参数
   
   OPTIONS="-g -x"
   
   [root@localhost ~]# systemctl restart ntpd		#启动ntp服务
   [root@localhost ~]# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime		#将系统时区改为上海时间 (亦即CST时区)
   ```

5. 关闭防火墙

   ```shell
   [root@localhost ~]# systemctl stop firewalld.service		# 关闭 “系统防火墙” 
   [root@localhost ~]# systemctl disable firewalld.service		# 关闭 “系统防火墙” 自启动
   ```

6. 修改主机名
   
   ```shell
   [root@localhost ~]# hostnamectl set-hostname master
   ```
   
7. 配置ssh

   ```shell
   [root@localhost ~]# vim /etc/ssh/ssh_config
   
           StrictHostKeyChecking no		#免输入yes进行known_hosts添加
           UserKnownHostsFile /dev/null		#可时时删除known_hosts文件免除known_hosts未更新导致的冲突
   ```

## 二、 安装jdk

1. 解压包

   ```shell
   [root@master ~]# cd /opt/
   [root@master opt]# tar -xzvf jdk-8u171-linux-x64.tar.gz
   [root@master opt]# mv jdk1.8.0_171/ /usr/local/java/
   ```

2. 配置环境变量

   ```shell
   [root@master opt]# vim /etc/profile
   
   #jdk8
   export JAVA_HOME=/usr/local/java
   export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
   export PATH=$JAVA_HOME/bin:$PATH
   
   [root@master opt]# source /etc/profile
   [root@master opt]# javac -version
   javac 1.8.0_171
   ```

   

3. 关机，然后将虚拟机复制两份，并分别修改主机名为slave1，slave2，静态IP尾号为130，131

## 三、 安装hadoop

1. 修改各个节点上的hosts文件, 

   ```shell
   [root@master ~]# vim /etc/hosts
   
   192.168.197.129 master
   192.168.197.130 slave1
   192.168.197.131 slave2
   ```

2. 配置SSH免密登录

   ```shell
   [root@master ~]# ssh-keygen -t rsa		#在各节点上执行，直接回车
   [root@master ~]# scp ~/.ssh/id_rsa.pub master:~/.ssh/id$HOSTNAME		#在各节点上执行，
   [root@master ~]# cd ~/.ssh/
   [root@master .ssh]# cat idmaster >> authorized_keys
   [root@master .ssh]# cat idslave1 >> authorized_keys
   [root@master .ssh]# cat idslave2 >> authorized_keys
   [root@master .ssh]# scp authorized_keys slave1:~/.ssh/
   [root@master .ssh]# scp authorized_keys slave2:~/.ssh/
   ```

   

3. 解压包

   ```shell
   [root@master .ssh]# cd /opt/
   [root@master opt]# tar -xzvf hadoop-2.7.5.tar.gz
   [root@master opt]# mv hadoop-2.7.5 hadoop
   ```

   

4. 在hadoop目录下创建 temp, dfs, dfs/name, dfs/data 文件夹

   ```shell
   [root@master opt]# mkdir hadoop/temp/
   [root@master opt]# mkdir -p hadoop/dfs/name/
   [root@master opt]# mkdir -p hadoop/dfs/data/
   ```

   

5. 修改配置文件hadoop-env.sh

   ```shell
   [root@master opt]# vim hadoop/etc/hadoop/hadoop-env.sh
   
   #export JAVA_HOME=${JAVA_HOME}
   export JAVA_HOME=/usr/local/java/
   ```
   
   
   
6. 修改配置文件yarn-env.sh

   ```shell
   [root@master opt]# vim hadoop/etc/hadoop/yarn-env.sh
   
   #  JAVA_HOME=$JAVA_HOME
     JAVA_HOME=/usr/local/java/
   ```

   

7. 修改配置文件core-site.xml

   ```xml
   [root@master opt]# vim hadoop/etc/hadoop/core-site.xml
   
   <configuration>
   	<property>
           <!-- NameNode的IP地址和端口 -->
   		<name>fs.defaultFS</name>
   		<value>hdfs://master:9000</value>
   	</property>
   	<property>
           <!-- 制定hadoop的temp文件夹地址 -->
   		<name>hadoop.tmp.dir</name>
   		<value>file:/opt/hadoop/temp/</value>
   	</property>
   </configuration>
   ```

   

8. 修改配置文件hdfs-site.xml

   ```xml
   [root@master opt]# vim hadoop/etc/hadoop/hdfs-site.xml
   
   <configuration>
   	<property>
   		<name>dfs.namenode.secondary.http-address</name>
   		<value>master:9001</value>
   	</property>
   	<property>
   		<name>dfs.namenode.name.dir</name>
   		<value>file:/opt/hadoop/dfs/name/</value>
   	</property>
   	<property>
   		<name>dfs.namenode.data.dir</name>
   		<value>file:/opt/hadoop/dfs/data/</value>
   	</property>
   	<property>
           <!-- 文件备份数量（份） -->
   		<name>dfs.replication</name>
   		<value>2</value>
   	</property>
   	<property>
   		<name>dfs.permissions</name>
   		<value>false</value>
   	</property>
   	<property>
   		<name>dfs.webhdfs.enabled</name>
   		<value>true</value>
   	</property>
   </configuration>
   ```

   

9. 修改配置文件mapred-site.xml

   ```xml
   [root@master opt]# vim hadoop/etc/hadoop/mapred-site.xml
   
   <configuration>
   	<property>
   		<name>mapreduce.framework.name</name>
   		<value>yarn</value>
   	</property>
   	<property>
   		<name>mapreduce.jobhistory.address</name>
   		<value>master:10020</value>
   	</property>
   	<property>
   		<name>mapreduce.jobhistory.webapp.address</name>
   		<value>master:19888</value>
   	</property>
   </configuration>
   ```

   

10. 修改配置文件yarn-site.xml

    ```xml
    [root@master opt]# vim hadoop/etc/hadoop/yarn-site.xml
    
    <configuration>
    	<property>
    		<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
    		<value>org.apache.hadoop.mapred.ShuffleHandler</value>
    	</property>
    	<property>
    		<name>yarn.nodemanager.aux-services</name>
    		<value>mapreduce_shuffle</value>
    	</property>
    	<property>
    		<!-- 客户端地址，向 resouce 请求地址 -->
    		<name>yarn.resourcemanager.address</name>
    		<value>master:8032</value>
    	</property>
    	<property>
    		<!-- 调入器调入地址 -->
    		<name>yarn.resourcemanager.scheduler.address</name>
    		<value>master:8030</value>
    	</property>
    	<property>
    		<!-- notemanager 汇报心跳等任务 -->
    		<name>yarn.resourcemanager.resource-tracker.address</name>
    		<value>master:8031</value>
    	</property>
    	<property>
    		<!-- 管理员地址，可发送管理命令等操作 -->
    		<name>yarn.resourcemanager.admin.address</name>
    		<value>master:8033</value>
    	</property>
    	<property>
    		<!-- 通过浏览器看到 hadoop 情况 -->
    		<name>yarn.resourcemanager.webapp.address</name>
    		<value>master:8088</value>
    	</property>
    </configuration>
    ```

    

11. 修改slaves文件

    ```shell
    [root@master opt]# vim hadoop/etc/hadoop/slaves
    
    slave1
    slave2
    ```

    

12. 配置环境变量

    ```shell
    [root@master opt]# vim /etc/profile
    
    #hadoop
    export HADOOP_HOME=/opt/hadoop
    export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
    
    [root@master opt]# source /etc/profile
    ```

    

13. 复制hadoop到其他节点

    ```shell
    [root@master opt]# scp -r /opt/hadoop/ slave1:/opt/
    [root@master opt]# scp -r /opt/hadoop/ slave2:/opt/
    ```

    

14. 格式化hdfs,启动，验证

    ```shell
    [root@master opt]# hdfs namenode -format
    [root@master opt]# start-all.sh
    [root@master opt]# hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar pi 10 10
    ```


## 四、 安装zookeeper

1. 解压缩文件

   ```shell
   [root@master opt]# cd /opt
   [root@master opt]# tar -zxvf zookeeper-3.4.11.tar.gz
   [root@master opt]# mv zookeeper-3.4.11 zookeeper
   ```

   

2. 创建节点标识文件

   ```shell
   [root@master opt]# mkdir -p zookeeper/data
   [root@master opt]# vim /opt/zookeeper/data/myid
   
   1
   ```

   

3. 复制zoo_sample.cfg

   ```shell
   [root@master opt]# cp zookeeper/conf/zoo_sample.cfg zookeeper/conf/zoo.cfg
   ```

   

4. 编辑 zoo.cfg

   ```shell
   [root@master opt]# vim zoo.cfg
   
   # 修改内容
   dataDir=/opt/zookeeper/data
   # 在尾部添加内容
   server.1=master:2888:3888
   server.2=slave1:2888:3888
   server.3=slave2:2888:3888
   ```

   

5. 拷贝 Zookeeper 安装文件到其他两个节点，并修改myid为2，3

   ```shell
   [root@master opt]# scp -r /opt/zookeeper slave1:/opt/
   [root@master opt]# scp -r /opt/zookeeper slave2:/opt/
   [root@master opt]# vim /opt/zookeeper/data/myid
   
   # 节点 slave1
   2
   
   # 节点 slave2
   3
   ```

   

6. 配置环境变量

   ```shell
   [root@master opt]# vim /etc/profile
   
   #zookeeper
   export ZOOKEEPER_HOME=/opt/zookeeper
   export PATH=$ZOOKEEPER_HOME/bin::$PATH
   
   [root@master opt]# source /etc/profile
   ```

   

7. 启动节点程序（每个节点执行）

   ```shell
   [root@master opt]# zkServer.sh start
   ```

## 五、安装hbase

1. 解压缩文件

   ```shell
   [root@master opt]# cd /opt
   [root@master opt]# tar -zxvf hbase-1.2.6-bin.tar.gz
   [root@master opt]# mv hbase-1.2.4 hbase
   ```

   

2. 修改hbase-env.sh

   ```shell
   [root@master opt]# vim hbase/conf/hbase-env.sh
   
   export JAVA_HOME=/usr/local/java/
   export HBASE_MANAGES_ZK=false
   ```

   

3. 拷贝 Zookeeper 配置文件 zoo.cfg

   ```shell
   [root@master opt]# cp zookeeper/conf/zoo.cfg /hbase/conf
   ```

   

4. 修改 hbase-site.xml

   ```xml
   [root@master opt]# vim hbase/conf/hbase-site.xml
   
   	<property>
   		<name>hbase.cluster.distributed</name>
   		<value>true</value>
   	</property>
   	<property>
   		<name>hbase.rootdir</name>
   		<value>hdfs://master:9000/hbase</value>
   	</property>
   
   	<property>
   		<name>hbase.zookeeper.quorum</name>
   		<value>master,slave1,slave2</value>
   	</property>
   
   	<property>
   		<name>hbase.zookeeper.property.dataDir</name>
   		<value>/opt/zookeeper/data</value>
   	</property>
   
   	<property>
   		<name>hbase.master.port</name>
   		<value>60000</value>
   	</property>
   
   	<property>
   		<name>hbase.master.info.port</name>
   		<value>60010</value>
   	</property>
   ```

   

5. 修改文件regionservers

   ```shell
   [root@master opt]# vim hbase/conf/regionservers
   
   slave1
   slave2
   ```

   

6. 配置环境变量

   ```shell
   [root@master opt]# vim /etc/profile
   
   export HBASE_HOME=/opt/hbase
   export PATH=$HBASE_HOME/bin:$PATH
   export HADOOP_CLASSPATH=$HBASE_HOME/lib/*
   
   [root@master opt]# source /etc/profile
   ```

   

7. 复制 HBase到其他节点

   ```shell
   [root@master opt]#  scp -r /opt/hbase/ slave1:/opt/
   [root@master opt]#  scp -r /opt/hbase/ slave2:/opt/
   ```

   

8. 启动hbase

   ```shell
   [root@master opt]#  start-hbase.sh
   ```

   